{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruaru0/bert-regression-test/blob/main/HuggingFace_BERT_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transformerのインストールなど"
      ],
      "metadata": {
        "id": "VT0Z-11xhd3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdkzoGiYhRaH"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install git+https://github.com/huggingface/accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fugashi\n",
        "!pip install ipadic\n",
        "!pip install unidic-lite"
      ],
      "metadata": {
        "id": "iLsMtGfkvMKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データセットを準備"
      ],
      "metadata": {
        "id": "JVif3DLAvQdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"tyqiangz/multilingual-sentiments\", \"japanese\")"
      ],
      "metadata": {
        "id": "4APncqjPvOmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "w1MU0hoxVZoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizerの取得"
      ],
      "metadata": {
        "id": "-KEhzQqGvV0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt = \"cl-tohoku/bert-large-japanese\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "HZaQAqR9vTzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データサイズを減らす"
      ],
      "metadata": {
        "id": "4u1Rc9G7vZHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "TRAIN_SIZE = 2000\n",
        "TEST_SIZE = 1000\n",
        "\n",
        "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=SEED).select(range(TRAIN_SIZE))\n",
        "dataset[\"validation\"] = dataset[\"validation\"].shuffle(seed=SEED).select(range(TEST_SIZE))\n",
        "dataset[\"test\"] = dataset[\"test\"].shuffle(seed=SEED).select(range(TEST_SIZE))"
      ],
      "metadata": {
        "id": "bvqnvyIXvXaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データセットの加工"
      ],
      "metadata": {
        "id": "stj43GLZvcfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "MAX = 512\n",
        "\n",
        "def tokenize(batch):\n",
        "    enc =  tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=MAX)\n",
        "    return enc"
      ],
      "metadata": {
        "id": "iKxdstFova6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_encoded = dataset.map(tokenize)"
      ],
      "metadata": {
        "id": "JwiqEmwuvebd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_dataset = dataset_encoded['train']\n",
        "small_valid_dataset = dataset_encoded['validation']\n",
        "small_test_dataset = dataset_encoded['test']"
      ],
      "metadata": {
        "id": "LnQhCbMkvfil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Value\n",
        "new_features = small_train_dataset.features.copy()\n",
        "new_features['label'] = Value(\"float64\")\n",
        "small_train_dataset = small_train_dataset.cast(new_features)\n",
        "small_valid_dataset = small_valid_dataset.cast(new_features)\n",
        "small_test_dataset = small_test_dataset.cast(new_features)\n"
      ],
      "metadata": {
        "id": "5X8hqIWeXoci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習"
      ],
      "metadata": {
        "id": "AMuh_7uuZgmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_labels = 1\n",
        "\n",
        "model = (AutoModelForSequenceClassification\n",
        "    .from_pretrained(model_ckpt, num_labels=num_labels)\n",
        "    .to(device))"
      ],
      "metadata": {
        "id": "P7EBqOvYvgv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import evaluate\n",
        "import numpy as np\n",
        "metric = evaluate.load(\"mse\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "NsczfFYOvk_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 4\n",
        "logging_steps = len(small_train_dataset) // batch_size\n",
        "model_name = \"multilingual-sentiments-regression-bert\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    disable_tqdm=False,\n",
        "    logging_steps=logging_steps,\n",
        "    push_to_hub=False,\n",
        "    log_level=\"error\"\n",
        ")"
      ],
      "metadata": {
        "id": "DSVrUb3xvl5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_valid_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "4T53j7xbvnEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# テストデータに対する結果を評価\n"
      ],
      "metadata": {
        "id": "PWtw-GLdvo5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(small_test_dataset)"
      ],
      "metadata": {
        "id": "v137itjyvoSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[] for _ in range(3)]\n",
        "cnt = 0\n",
        "for p, l in zip(preds_output.predictions, preds_output.label_ids) :\n",
        "  x[int(l)].append(p[0]+1)\n",
        "  if cnt == 100 : break\n",
        "  cnt += 1\n",
        "\n",
        "for i in range(3):\n",
        "  v = np.array(x[i])\n",
        "  print(f\"{i+1}: mean={v.mean()}, std = {v.std()}\")"
      ],
      "metadata": {
        "id": "cAL9TRfwvrU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(preds_output.predictions+1, preds_output.label_ids+1, alpha=0.05)"
      ],
      "metadata": {
        "id": "DTUW-Avgvsft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(x)"
      ],
      "metadata": {
        "id": "E35Y_tTovtfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデルの保存、読み込み"
      ],
      "metadata": {
        "id": "4kVRPtiQvvlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(f\"./{model_name}-test\")"
      ],
      "metadata": {
        "id": "AO0EqE0Jvu4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer\\\n",
        "    .from_pretrained(f\"./{model_name}-test\")\n",
        "\n",
        "model = (AutoModelForSequenceClassification\n",
        "    .from_pretrained(f\"./{model_name}-test\")\n",
        "    .to(device))"
      ],
      "metadata": {
        "id": "WMkULkERvyMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YozQMxHJvzPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}